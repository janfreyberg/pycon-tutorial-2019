{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A gradient reversal layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Function\n",
    "\n",
    "class RevGrad(Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, input_):\n",
    "        ######\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):  \n",
    "        #####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "\n",
    "class RevGradLayer(Module):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        A gradient reversal layer.\n",
    "        This layer has no parameters, and simply reverses the gradient\n",
    "        in the backward pass.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def forward(self, input_):\n",
    "        #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "network_green = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 32, kernel_size=5),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    torch.nn.Conv2d(32, 48, kernel_size=5),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.AdaptiveMaxPool2d(1),\n",
    "    )\n",
    "\n",
    "network_purple = torch.nn.Sequential(\n",
    "    torch.nn.Linear(48, 100),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(100, 100),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(100, 10), \n",
    "    torch.nn.Softmax(),\n",
    ")\n",
    "\n",
    "network_pink = torch.nn.Sequential(\n",
    "    RevGradLayer(),\n",
    "    torch.nn.Linear(48, 100),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(100, 1),\n",
    "    torch.nn.Sigmoid(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistNetwork(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, network_green, network_purple, network_pink):\n",
    "        super().__init__()\n",
    "        self.network_green = network_green\n",
    "        self.network_purple = network_purple\n",
    "        self.network_pink = network_pink\n",
    "\n",
    "    def forward(self, x):\n",
    "        intermediate = self.network_green(x)\n",
    "        intermediate = intermediate.reshape(-1, 48)\n",
    "        class_label_prediction = self.network_purple(intermediate)\n",
    "        domain_prediction = self.network_pink(intermediate)\n",
    "        \n",
    "        return class_label_prediction, domain_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use it to train:\n",
    "\n",
    "model = MnistNetwork(network_green, network_purple, network_pink)\n",
    "\n",
    "class_loss = torch.nn.CrossEntropyLoss()\n",
    "domain_loss = torch.nn.BCELoss()\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "data = torch.utils.data.DataLoader(\n",
    "    MNIST(\n",
    "        \"mnist\", download=True, transform=ToTensor()\n",
    "    ),\n",
    "    batch_size=64,\n",
    ")\n",
    "\n",
    "for epoch in range(5):\n",
    "    for i, (batch_x, batch_y) in enumerate(data):\n",
    "        # we only have one domain in this example,\n",
    "        # so for now we just choose randomly 1:\n",
    "        domain = (torch.rand((len(batch_y), )) > 0.5).float()\n",
    "        class_predictions, domain_predictions = model(batch_x)\n",
    "        loss_class = class_loss(class_predictions, batch_y)\n",
    "        loss_domain = domain_loss(domain_predictions, domain)\n",
    "        loss = loss_class + 0.1 * loss_domain\n",
    "\n",
    "        # do the backward pass:\n",
    "        loss.backward()\n",
    "        # take a gradient descent step:\n",
    "        optimiser.step()\n",
    "        # reset the gradients\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        if (i % 200) == 0:\n",
    "            # print the loss regularly to see what's going on:\n",
    "            print(f\"Classification loss: {loss_class}, domain loss: {loss_domain}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# _Solutions_\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return input_\n",
    "\n",
    "return grad_output * -1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return RevGrad.apply(input_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
